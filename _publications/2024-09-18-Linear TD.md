---
title: "Almost Sure Convergence of Linear Temporal Difference Learning with Arbitrary Features"
authors: "<b>Jiuqi Wang</b>, Shangtong Zhang"
collection: publications
permalink: /publication/2024-09-18-Linear TD
excerpt:
date: 2024-09-18
venue: 'arXiv'
paperurl: 'https://arxiv.org/abs/2409.12135'
citation:
abstract: "Temporal difference (TD) learning with linear function approximation, abbreviated as linear TD, is a classic and powerful prediction algorithm in reinforcement learning. While it is well understood that linear TD converges almost surely to a unique point, this convergence traditionally requires the assumption that the features used by the approximator are linearly independent. However, this linear independence assumption does not hold in many practical scenarios. This work is the first to establish the almost sure convergence of linear TD without requiring linearly independent features. In fact, we do not make any assumptions on the features. We prove that the approximated value function converges to a unique point and the weight iterates converge to a set. We also establish a notion of local stability of the weight iterates. Importantly, we do not need to introduce any other additional assumptions and do not need to make any modification to the linear TD algorithm. Key to our analysis is a novel characterization of bounded invariant sets of the mean ODE of linear TD."
---